{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn Webscraper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I\n",
    "Getting Data from LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "import requests\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [\n",
    "    'SAP-Entwickler/SAP-Berater',\n",
    "    'IT-Projektmanager',\n",
    "    'Softwareentwickler',\n",
    "    'Business Intelligence Analyst',\n",
    "    'IT-Controller',\n",
    "    'IT-Berater',\n",
    "    'Produktmanager',\n",
    "    'App-Entwickler',\n",
    "    'Anwendungsentwickler',\n",
    "    'Datenbankspezialist',\n",
    "    'ERP Manager'\n",
    "]\n",
    "\n",
    "base_url = 'https://de.linkedin.com/jobs/'\n",
    "extended_url = '-stellen?position=1&pageNum=0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m         job \u001b[39m=\u001b[39m [title, company, location, link, date, time]\n\u001b[0;32m     20\u001b[0m         i \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df_joblistings)\n\u001b[1;32m---> 21\u001b[0m         df_joblistings\u001b[39m.\u001b[39mloc[i] \u001b[39m=\u001b[39m job\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(df_joblistings)\n",
      "File \u001b[1;32mc:\\Users\\kuhle\\anaconda3\\envs\\process_review\\lib\\site-packages\\pandas\\core\\indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\kuhle\\anaconda3\\envs\\process_review\\lib\\site-packages\\pandas\\core\\indexing.py:1785\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1782\u001b[0m     indexer, missing \u001b[39m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m missing:\n\u001b[1;32m-> 1785\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_missing(indexer, value)\n\u001b[0;32m   1786\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mloc\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1789\u001b[0m     \u001b[39m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kuhle\\anaconda3\\envs\\process_review\\lib\\site-packages\\pandas\\core\\indexing.py:2160\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2157\u001b[0m     \u001b[39mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[0;32m   2158\u001b[0m         \u001b[39m# must have conforming columns\u001b[39;00m\n\u001b[0;32m   2159\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mcolumns):\n\u001b[1;32m-> 2160\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot set a row with mismatched columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2162\u001b[0m     value \u001b[39m=\u001b[39m Series(value, index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mcolumns, name\u001b[39m=\u001b[39mindexer)\n\u001b[0;32m   2164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj):\n\u001b[0;32m   2165\u001b[0m     \u001b[39m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[0;32m   2166\u001b[0m     \u001b[39m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "columns = ['title', 'company', 'location', 'link', 'date', 'time']\n",
    "df_joblistings = pd.DataFrame(columns)\n",
    "\n",
    "for position in positions:\n",
    "    url = f'{base_url}{position}{extended_url}'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    posts = soup.find_all('div', class_ = 'base-card')\n",
    "    for post in posts:\n",
    "        title = post.find('h3', class_ = 'base-search-card__title').text.strip()\n",
    "        company = post.find('h4', class_ = 'base-search-card__subtitle').text.strip()\n",
    "        try:\n",
    "            location = post.find('span', class_ = 'job-search-card__location').text.strip()\n",
    "        except:\n",
    "            location = 'unknown'\n",
    "        link = post.find('a', class_ = 'base-card__full-link').get('href')\n",
    "        date = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "        time = datetime.now().time().strftime(\"%H:%M:%S\")\n",
    "        job = [title, company, location, link, date, time]\n",
    "        i = len(df_joblistings)\n",
    "        df_joblistings[i] = job\n",
    "print(df_joblistings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     test\n",
      "0    test\n",
      "1  number\n"
     ]
    }
   ],
   "source": [
    "df_job = pd.DataFrame()\n",
    "df_job['test'] = ['test', 'number']\n",
    "print(df_job)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II\n",
    "\n",
    "Saving Data to a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection = create_engine('mysql+pymysql://root:@localhost/businessintelligence')\n",
    "# df_job.to_sql('job', con=connection, index=False, if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "process_review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2424bdc8459e15fb9e7ab4e25b4f56d86ba224a1120c352f096c5f08247ff3b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
